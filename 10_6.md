<h1 dir="auto">Домашнее задание к занятию "10.06. Инцидент-менеджмент"</h1>
<h2 dir="auto"><a id="user-content-задание-1" class="anchor" href="https://github.com/Dmitriy-Guskov/devops-netology/blob/main/hw1006.md#%D0%B7%D0%B0%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5-1" aria-hidden="true"></a>Задание 1</h2>
<p dir="auto">Составьте постмотрем, на основе реального сбоя системы Github в 2018 году.</p>
<p dir="auto">Информация о сбое доступна&nbsp;<a href="https://habr.com/ru/post/427301/" rel="nofollow">в виде краткой выжимки на русском языке</a>&nbsp;, а также&nbsp;<a href="https://github.blog/2018-10-30-oct21-post-incident-analysis/" rel="nofollow">развёрнуто на английском языке</a>.</p>
<table>
<thead>
<tr>
<th style="width: 137.887px;" align="left">Наименование</th>
<th style="width: 414.513px;" align="center">Описание</th>
</tr>
</thead>
<tbody>
<tr>
<td style="width: 137.887px;" align="left">Краткое описание инцидента</td>
<td style="width: 414.513px;" align="center">21 октября 2018года в 22:52 внутренние системы платформы GitHub функционируют в нештатном режиме, что привело к отображению устаревшей и непоследовательной информации. Возникла несогласованность данных в БД. Деградация сервиса наблюдалась в течении 24 часов и 11 минут.</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">Предшествующие события</td>
<td style="width: 414.513px;" align="center">Плановые ремонтные работы по замене неисправного оптического оборудования 100G привели к потере связи на 43сек между сетевым узлом US East Coast и основным дата-центром US East Coast.</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">Причина инцидента</td>
<td style="width: 414.513px;" align="center">Потеря соединения с ЦОД US East Coast привела к рассогласованности кластеров MySQL.</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">Воздействие</td>
<td style="width: 414.513px;" align="center">Несогласованность предоставляемой информации, Невозможность работы событий WebHook и недоступность работы страниц GitHub.</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">Обнаружение</td>
<td style="width: 414.513px;" align="center">Инцидент замечен дежурными инженерами. Затем были привлечены ответственные разработчики.</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">Реакция</td>
<td style="width: 414.513px;" align="center">Деградация сервиса в течении 24 часов и 11 минут.</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">Восстановление</td>
<td style="width: 414.513px;" align="center">Восстановление полной производительности было выполнено за счет восстановления данных из резервных копий и повторной репликацией БД с хостов с актуальными данными.</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">Таймлайн</td>
<td style="width: 414.513px;" align="center">2018.10.21 22:52 UTC - потеря консенсуса между сереврами в дата хабах в результате потери связи с ЦОД. После восстановления связи была попытка восстановления целостности кластера, восстановления консенсуса, но данные в БД различались, что привело к несогласованности в рамках кластера</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">.</td>
<td style="width: 414.513px;" align="center">2018.10.21 22:54 UTC - Инженеры поддержки зафиксировали на мониторинге несоответствие кластера ожидаемому состоянию, в 23:02 выявлено отсутсвие серверов из US East Coast</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">.</td>
<td style="width: 414.513px;" align="center">2018.10.21 23:07 UTC - отключены внутренние инструменны развертывания для предотвращения дополнительных имзменений. Сайт переведен в желтый статус и автомтически зафикисрован инциден в системе управления сбоями.</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">.</td>
<td style="width: 414.513px;" align="center">2018.10.21 23:13 UTC - выявлены воздействия на множественные сервера , выведены дополнительные инженеры, выполнены действия для сохранения пользовательских данных.</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">.</td>
<td style="width: 414.513px;" align="center">2018.10.21 23:19 UTC - Остановлены некоторые процессы (принудительная деградация) с целью повышения скорости восстановления</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">.</td>
<td style="width: 414.513px;" align="center">2018.10.22 00:05 UTC - Разработка плана по восстановления системы и синхронизаии репликаций данных. Обновлен статус, чтобы сообщить пользователям, что GitHub собираемся выполнить контролируемую отработку отказа внутренней системы хранения данных.</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">.</td>
<td style="width: 414.513px;" align="center">2018.10.22 00:41 UTC - Запущен процесс резервного копирования данных</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">.</td>
<td style="width: 414.513px;" align="center">2018.10.22 06:51 UTC - бэкапы US East Coast data center выполнены, запущенно реплецирование с серверов в West Coast.</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">.</td>
<td style="width: 414.513px;" align="center">2018.10.22 07:46 UTC - опубликована расширенная информация о ходе восстановления для пользователей</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">.</td>
<td style="width: 414.513px;" align="center">2018.10.22 11:12 UTC - Востановлены серверы в US East Coast, продолжается реплицирование. Наблюдается повышенная нагрузка при реплицировании.</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">.</td>
<td style="width: 414.513px;" align="center">2018.10.22 13:15 UTC - Пик нагрузки на GitHub. Отставание репликации до согласованного состояния увеличивается. Подготовка дополнительных реплик чтения MySQL в общедоступном облаке Восточного побережья, распределение потоков с учетом дополнительно развернутых реплик MySQL. Уменьшение средней нагрузки на реплики чтения ускорило догон репликации.</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">.</td>
<td style="width: 414.513px;" align="center">2018.10.22 16:24 UTC - реплицирование синхронизировано, переключение в штатную топологию MySQL.</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">.</td>
<td style="width: 414.513px;" align="center">2018.10.22 16:45 UTC - На этапе восстановления не удалось сбалансировать возросшую нагрузку и в результате около 200000 полезных задач были отброшены ввиду превышения TTL. Остановка обработки и увеличение TTL до полного завершения репликаций и возвращения к штатной работе.</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">.</td>
<td style="width: 414.513px;" align="center">2018.10.22 23:03 UTC - Все незавершённые события вебхуков и сборки Pages обработаны, целостность и правильная работа всех систем подтверждена. Статус сайта обновлён на зелёный.</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">Последующие действия</td>
<td style="width: 414.513px;" align="center">В ходе анализа событий был принят ряд технических мер: - Отрегулировать конфигурацию Orchestrator, чтобы запретить перемещение первичных БД за границы региона;</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">.</td>
<td style="width: 414.513px;" align="center">- ускорить миграцию на новую систему отчётности по статусам, которая предоставит более развернутую информацию по инциденту, мы могли выбрать только зелёный, жёлтый и красный статусы для всего сайта, это не даёт точной картины: что работает, а что нет. Новая система будет отображать различные компоненты платформы, чтобы вы знали статус каждой службы;</td>
</tr>
<tr>
<td style="width: 137.887px;" align="left">.</td>
<td style="width: 414.513px;" align="center">- запустили общекорпоративную инженерную инициативу для поддержки обслуживания трафика GitHub из нескольких ЦОД по архитектуре active/active/active. Цель данного проекта &mdash; поддержка избыточности N+1 на уровне ЦОД, чтобы выдерживать отказ одного ЦОД без вмешательства со стороны.</td>
</tr>
</tbody>
</table>
<!-- #######  YAY, I AM THE SOURCE EDITOR! #########-->
<p>&nbsp;</p>
<p><strong>&nbsp;</strong></p>
